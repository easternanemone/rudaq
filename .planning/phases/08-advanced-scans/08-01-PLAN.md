---
phase: 08-advanced-scans
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - crates/daq-storage/Cargo.toml
  - crates/daq-storage/src/lib.rs
  - crates/daq-storage/src/zarr_writer.rs
autonomous: true

must_haves:
  truths:
    - "Zarr V3 store can be created at a file path"
    - "N-dimensional arrays can be written with correct shape and chunking"
    - "Xarray can read the written Zarr files (via _ARRAY_DIMENSIONS attribute)"
  artifacts:
    - path: "crates/daq-storage/src/zarr_writer.rs"
      provides: "ZarrWriter for N-dimensional data storage"
      exports: ["ZarrWriter", "ZarrArrayBuilder"]
    - path: "crates/daq-storage/Cargo.toml"
      provides: "zarrs and object_store dependencies"
      contains: "zarrs"
  key_links:
    - from: "crates/daq-storage/src/zarr_writer.rs"
      to: "zarrs crate"
      via: "ArrayBuilder and FilesystemStore"
      pattern: "use zarrs"
---

<objective>
Implement Zarr V3 storage foundation using the zarrs crate.

Purpose: Zarr V3 is the modern standard for cloud-native N-dimensional scientific data. This replaces HDF5 as the primary storage format for nested scans with proper dimensional metadata.

Output: ZarrWriter module with Xarray-compatible encoding
</objective>

<execution_context>
@/Users/briansquires/.claude/get-shit-done/workflows/execute-plan.md
@/Users/briansquires/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-advanced-scans/08-RESEARCH.md
@crates/daq-storage/src/hdf5_writer.rs
@crates/daq-storage/src/lib.rs
@crates/daq-storage/Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add zarrs dependencies and feature flag</name>
  <files>crates/daq-storage/Cargo.toml</files>
  <action>
Add zarrs and object_store dependencies to Cargo.toml:

```toml
# Under [dependencies]
zarrs = { version = "0.22", optional = true }
object_store = { version = "0.11", optional = true }

# Under [features]
storage_zarr = ["dep:zarrs", "dep:object_store"]
```

The storage_zarr feature enables Zarr V3 support. object_store provides the storage backend abstraction for both local filesystem and future cloud (S3/GCS) support.

Do NOT modify any existing features or dependencies.
  </action>
  <verify>
Run: `cargo check -p daq-storage --features storage_zarr`
Should compile without errors.
  </verify>
  <done>zarrs and object_store dependencies added with storage_zarr feature flag</done>
</task>

<task type="auto">
  <name>Task 2: Create ZarrWriter module with Xarray-compatible encoding</name>
  <files>crates/daq-storage/src/zarr_writer.rs, crates/daq-storage/src/lib.rs</files>
  <action>
Create zarr_writer.rs implementing ZarrWriter for N-dimensional data storage:

1. **ZarrWriter struct** - manages Zarr V3 store with:
   - `output_path: PathBuf` - store location
   - `store: Arc<FilesystemStore>` - zarrs storage backend
   - `arrays: HashMap<String, ArrayHandle>` - cached array handles

2. **ZarrArrayBuilder** - fluent API for creating arrays:
   - `shape(dims: Vec<u64>)` - array shape
   - `chunks(sizes: Vec<u64>)` - chunk sizes (target 10-100 MB)
   - `dimensions(names: Vec<String>)` - dimension names for Xarray
   - `dtype<T: DataType>()` - element type
   - `build(name: &str)` - create array at path

3. **Key implementation details**:
   - Use `ArrayBuilder::new()` from zarrs for array creation
   - Write `_ARRAY_DIMENSIONS` attribute to .zattrs for Xarray compatibility:
     ```rust
     let mut attrs = serde_json::Map::new();
     attrs.insert("_ARRAY_DIMENSIONS".to_string(),
                  json!(["wavelength", "position", "y", "x"]));
     ```
   - Use `FilesystemStore::new()` for local storage
   - Wrap file I/O in `tokio::task::spawn_blocking()` (match HDF5Writer pattern)

4. **write_chunk()** method for incremental writes:
   ```rust
   pub async fn write_chunk<T: Element>(
       &self,
       array_name: &str,
       indices: &[u64],
       data: &[T],
   ) -> Result<()>
   ```

5. **Public API**:
   - `ZarrWriter::new(path: &Path) -> Result<Self>`
   - `ZarrWriter::create_array(&self) -> ZarrArrayBuilder`
   - `ZarrWriter::write_chunk()` - async chunk write
   - `ZarrWriter::add_group_attribute()` - for experiment metadata

6. **Export from lib.rs** behind feature flag:
   ```rust
   #[cfg(feature = "storage_zarr")]
   pub mod zarr_writer;
   #[cfg(feature = "storage_zarr")]
   pub use zarr_writer::{ZarrWriter, ZarrArrayBuilder};
   ```

Reference the zarrs crate patterns from 08-RESEARCH.md for correct API usage.
  </action>
  <verify>
Run: `cargo test -p daq-storage --features storage_zarr`
All tests should pass.
  </verify>
  <done>ZarrWriter module with Xarray-compatible _ARRAY_DIMENSIONS encoding</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests verifying Xarray compatibility</name>
  <files>crates/daq-storage/src/zarr_writer.rs</files>
  <action>
Add tests in zarr_writer.rs verifying:

1. **test_create_zarr_store** - creates valid Zarr V3 directory structure:
   - Creates .zgroup file at root
   - Creates array with .zarray and .zattrs

2. **test_write_1d_array** - writes 1D data:
   - Creates array with shape [100]
   - Writes data in chunks
   - Verifies all data written correctly

3. **test_write_nd_array_with_dimensions** - verifies Xarray compatibility:
   - Creates 4D array [10, 5, 256, 256] (wavelength, position, y, x)
   - Writes `_ARRAY_DIMENSIONS` attribute
   - Verifies attribute present in .zattrs JSON

4. **test_chunking_strategy** - verifies chunk sizes:
   - Creates array with specified chunk shape
   - Verifies chunks are created at expected paths

Use tempfile::TempDir for test isolation.
  </action>
  <verify>
Run: `cargo test -p daq-storage --features storage_zarr -- zarr`
All zarr tests should pass.
  </verify>
  <done>Unit tests verifying Zarr V3 format and Xarray attribute encoding</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Feature flag works: `cargo check -p daq-storage --features storage_zarr`
2. Tests pass: `cargo test -p daq-storage --features storage_zarr`
3. No regressions: `cargo test -p daq-storage --features storage_hdf5`
4. Format/lint: `cargo fmt --all && cargo clippy -p daq-storage --features storage_zarr`
</verification>

<success_criteria>
- ZarrWriter can create Zarr V3 stores at local filesystem paths
- Arrays written with `_ARRAY_DIMENSIONS` attribute for Xarray compatibility
- Chunk-based writes enable incremental data storage
- All tests pass with storage_zarr feature enabled
</success_criteria>

<output>
After completion, create `.planning/phases/08-advanced-scans/08-01-SUMMARY.md`
</output>
